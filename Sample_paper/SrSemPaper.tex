\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{mathtools}

\begin{document}
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2015}{Morris, MN}

\title{Thermal interaction in Spatial Augmented Reality}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Justin B. YaDeau\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{yadea003@morris.umn.edu}
}

\maketitle

\begin{abstract}
This paper discussion the use of 3D projectors and thermal sensors to interact with 3D data visualization, without having to actually touch an electronic device. This leads to a cut down on the amount of electronic devices needed for modern life.
\todo[inline]{Subject to change}
\end{abstract}

\keywords{Thermal interaction, 3D Data Visualization, Augmented Reality, Spatial Augmented reality, SAR, AR}

\section{Introduction}
\label{sec:introduction}


\section{Background}
\label{sec:background} 

\subsection{Virtual Reality}
\label{sec:Virtual Reality}

The most well known example of Virtual Reality (VR) is the Oculus Rift. VR has been around for a while. Some early examples would be the view master, the stereoscopic toy that had circular inserts requiring the user to look into a light source to illuminate the picture. Nintendo had its own type of Oculist Rift in the 90's called Virtual Boy.      

\subsection{Augmented Reality}
\label{sec:Augmented Reality}
Augmented Reality (AR) can be described as augmenting the environment of the real world. It's different from VR because it is based in the physical world instead of the digital world. An example is Google Translate: using the camera from a phone it translates foreign words that you point at. On the phones screen it overlays the translation onto the sign, billboard, or menu. 

\todo[inline]{3Ds AR Cards?}

\subsection{Spatial Augmented Reality}
\label{sec:Spatial Augmented Reality}
Spatial Augmented Reality, SAR, is similar to AR. The difference is that it focuses more on augmenting reality through projection technology, instead of using conventional monitors or other such devices. A good example of SAR is if you have a sandbox with a topographical map overlaid onto the sand. You could move the sand around and the projector would match the peaks and valleys in the sand with the correct topographic overlay for displaying peaks and valleys.  

\subsection{6DOF}
\label{sec:6DOF}
6DOF, 6 degrees of freedom, are the different ways one can move in three dimensional space . From/back, left/right, up/down, roll, pitch, yaw are all the ways to move. Roll is moving clockwise or counter clockwise in relation to the front/back axis. Yaw is moving the front/back axis to either left/right axis. Pitch is the same yaw, except the up/down axis instead of the left/right axis.

\subsection{Data Visualization}
\label{sec:Data Visualization}
Data visualization is the representation of data visually. Basic examples are pie charts, scatter-plots, bar charts, and the list goes on. Data visualization can be used in any field, from showing the demographic of a neighborhood to displaying how many shooting stars happen over the course of a year.   

\section{Thermal Interaction}
\label{sec:Thermal Interaction}

Kurz \cite{Thermal} provides a way to interact with AR applications with any real object. Using the infrared thermography, his system can detect if the user touched a surface or came close to touching it. Keeping in mind one's finger(s) are warm and the surface is presumably cool, meaning one leaves a heat signature on the cool surface. The system assumes that it takes place in a controlled environment where objects will be cooler then body temperature. Heat can be transferred to a surface without physical contact as mentioned above. When the thermal image detects a heat signature the same system is able to determine the 3D position on the touched physical object. Kurz \cite{Thermal} states that as wearable technology becomes more prominent alternative solutions to touch screens will be sought after. The tests that were done used an array of materials and users to show the intuitive interaction with mobile AR and common objects.

\subsection{Hardware}
\label{Hardware}

\begin{figure}
	\includegraphics[width=8.5cm, height=5cm]{Hardware2}
	\caption{The setup used by Kurz \cite{Thermal}}
	\label{fig:hardware}
\end{figure}

Kurz's \cite{Thermal} setup uses a PI 200 camera mounted to a tablet computer as shown in figure \ref{fig:hardware}. The camera mixes a viable light camera, and a infrared camera in one package. The visible light camera is able to capture RGB images a 480x360 pixels and the infrared at 160x120 pixels. The light parameters of the visible light camera \(K_v\) and the infrared camera \(K_t\) along with the 6DOF rigid body transformation from both cameras \(T_v\) (tTv) were calibrated offline. The calibration method Kurx used had a checkerboard pattern cut into bright cardboard then attached to a warm dark surface like an LCD screen. This is done so that the visible light camera sees dark squares on a light surface, but the infrared camera sees light squares on a dark surface. Allowing calibration of the parameters of both cameras and obtaining the 6DOF rigid body transformation (tTv).

\todo[inline]{Find out how to do superscripts before a variable and image for the checkerboard example}

\subsection{Object Tracking}
\label{Object Tracking}

As mentioned above in section \ref{sec:Thermal Interaction}  Kurz's desire is detecting touch in 3D space with real objects. Requiring the know how to transform real objects relative to the camera. He used Metaio SDK so that the visual light camera was able to get the position and orientation of the object(s). 

\todo[inline]{cite SDK and expand using it}

\subsection{Thermal Detection}
\label{Thermal Detection}
The two main obstacles that Kurz brings us is detecting the touch in thermal imaging and being able to find where the touch occurred on a 3D object. First he explored temperature profiles of a surface being touched, obstructed, or not interacted with at all. The 4 cases of temperatures profiles are: Object only, Hand only, obstruction by hand, and touch by hand. Object only is just using the cameras to measure the relative constant temperature of an object. Hand only measured the temperature of a hand expecting moderate temperature changes. Obstruction by hand starts with detecting an object having a hand come between the object and the camera, not touching the object. The infrared will detect the rapid change from cool surface to a warm body then rapidly back to the cool surface. Touch by hand is when the object is actually touched. For the temperature it will start with the cool surface the warm body obstructs the area then once the hand moves away instead of a rapid change back to a cool surface there is a rapid decrease to a temperature between that of the hand and the object. After the rapid decrease the area will slowly cool, reverting to the starting temperature.

\todo[inline]{Blob detector}

\subsection{Materials Tested}
\label{Materials Tested}



\subsection{Applications}
\label{Applications}



\section{3D Data Visualization}
\label{sec:3D Data Visualization}

\begin{figure}
	\includegraphics[width=8.5cm, height=5cm]{Tabletop}
	\caption{\cite{3D}}
	\label{fig:Tabletop}
\end{figure}

I will now focus on a paper that delves into the use of SAR as a tool for 3D data visualization. As we know from \ref{sec:Spatial Augmented Reality} SAR uses projectors to augment what is already there. The way \cite{3D} defines SAR is 
\begin{quote}
Spatial Augmented Reality (SAR) enhances the visual aspects of physical objects, allowing users to better understand the virtual content. The users not only view the digital information but also gain a tactile understanding through touching the physical object.
\end{quote}

Mentioning that we gain a better understanding through touch is a good point to bring up.
Thomas et al \cite{3D} focus more on 3D data visualization, and not manipulation. Being able to see and touch the data is their main focus. Pushing the idea that using multiple inputs, sight and touch, to help you remember the data being displayed. They \cite{3D} define their purposed use of SAR as a tool for 3D visualization in following ways. First they purpose the use of SAR to benefit user's ability to see, understand, and manipulate 3D visualization data. Second is the tabletop SAR prototype that is able to demonstrate many possibilities. Figure \ref{fig:Tabletop}  is an image of their prototype tabletop SAR system. The projections on the physical props define areas of investigation in a 3D volume. The 4K monitor provides detail views of the data in a 2D space. Third is the large applications of SAR, called \textit{CAVE} it is discussed later in this section.


\subsection{Visualizing Data}
\label{sec:Visualizing Data}

Visualizing data is an effective way to show information quickly and efficiently. We tend to recall pictures easier than words. That is why there are many different types of charts. As mentioned in \ref{sec:Data Visualization}, the wide range of the types of data you can visualize makes what the papers proposes versatile in the real world.      

\subsection{Applications}
\label{sec:Applications}

\begin{figure}
	\includegraphics[width=8.5cm, height=5cm]{Cave}
	\caption{\cite{3D}}
	\label{fig:Cave}
\end{figure}

The paper mentions two ways that 3D data visualization can be applied in the real world. The main one they mention is the tabletop. This is a proposed system where there is a 2D display, they call it a fish tank view, a table with the physical object(s), the virtual volume, the hand held pointing device, 6DOF trackers, and the projectors. The virtual volume is the space around the table top, starting from the surface of the table extending up a foot or two. The CAVE is larger scale version of the tabletop method. Using walls as the physical objects to project onto. This would require a lot more space, 6DOF tracers, and projectors to get it set up. The benefit the cave model is being able to increase the number of collaborators/viewers. Figure \ref{fig:Cave} is 

\subsection{Limitations}
\label{sec:Limitations}

The initial experimentation with \cite{3D}'s prototype showed a number of limitations with the approach they took. The first is that the lighting the room must be controlled, as details in the gradients of the projected data may be lost with too much ambient lighting. Like anything projector related it works best in dim to dark room/places, depending on the type of projector. Normally we would not take a projector outside in the middle of the day and try to use it. Even inside can be too bright, teachers tend to shut off the lights closest to the screen when they use a projector. \cite{3D} mention that depending on the ambient lighting in the room one possible solution would be upgrading to a more powerful projector.  

\subsection{Conclusion}
\label{sec:Conclusion}

The goal of Thomas et al \cite{3D} was presenting SAR as a tool to enrich the process of 3D visualization. They layout their plan on using SAR with these three points. One is purposed features to benefit the use's abilities interpret the data. The second point being the example of a tabletop prototype (see figure \ref{fig:Tabletop}) showing the flexibility of this as a 3D visualization tool. Lastly the larger scale CAVE applications as ways to increase possible collaboration size.      


\section{Joining}
\label{sec:Joining}

\section{Alternate Interactions}
\label{sec:Alternate Interactions}

\section{Acknowledgments}
\label{sec:Acknowledgments}

\bibliographystyle{abbrv}
\bibliography{annotatedBibliography}

\end{document}